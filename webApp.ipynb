{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b75f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter serverextension enable voila "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd279f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!jupyter serverextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4afab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "\n",
    "dtf1 = pd.read_csv('arkansas1Bayer.csv')\n",
    "dtf2 = pd.read_csv('arkansasBayer.csv')\n",
    "\n",
    "X = dtf1.drop([], axis=1).dropna(axis='rows')\n",
    "Y = dtf2.drop([], axis=1).dropna(axis='rows')\n",
    "listOfColumnNames = list(X)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.7, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "importance = abs(lr.coef_.flatten())\n",
    "#print(importance)\n",
    "#for i,v in enumerate(importance):\n",
    "#\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "y_lr_train_pred = lr.predict(X_train)\n",
    "y_lr_test_pred = lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "lr_train_mse = mean_squared_error(Y_train, y_lr_train_pred)\n",
    "lr_train_r2 = r2_score(Y_train, y_lr_train_pred)\n",
    "lr_test_mse = mean_squared_error(Y_test, y_lr_test_pred)\n",
    "lr_test_r2 = r2_score(Y_test, y_lr_test_pred)\n",
    "lr_results = pd.DataFrame(['Linear regression',lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()\n",
    "lr_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=800,max_depth=15,min_samples_split=2,random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_rf_train_pred = rf.predict(X_train)\n",
    "y_rf_test_pred = rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(Y_train, y_rf_train_pred)\n",
    "rf_train_r2 = r2_score(Y_train, y_rf_train_pred)\n",
    "rf_test_mse = mean_squared_error(Y_test, y_rf_test_pred)\n",
    "rf_test_r2 = r2_score(Y_test, y_rf_test_pred)\n",
    "rf_results = pd.DataFrame(['Random forest',rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()\n",
    "rf_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=5,weights='distance',algorithm='brute',leaf_size=25, p=1)\n",
    "model.fit(X_train, Y_train)\n",
    "y_NR_train_pred = model.predict(X_train)\n",
    "y_NR_test_pred = model.predict(X_test)\n",
    "\n",
    "NR_train_mse = mean_squared_error(Y_train, y_NR_train_pred)\n",
    "NR_train_r2 = r2_score(Y_train, y_NR_train_pred)\n",
    "NR_test_mse = mean_squared_error(Y_test, y_NR_test_pred)\n",
    "NR_test_r2 = r2_score(Y_test, y_NR_test_pred)\n",
    "\n",
    "NR_results = pd.DataFrame(['KNeighborsRegressor',NR_train_mse, NR_train_r2, NR_test_mse, NR_test_r2]).transpose()\n",
    "NR_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "model1 = XGBRegressor(base_score=0.5,learning_rate=0.2,\n",
    "       max_depth=1, min_child_weight=1,  n_estimators=100,random_state=42,\n",
    "       importance_type='gain')\n",
    "model1.fit(X_train, Y_train)\n",
    "y_XGB_train_pred = model1.predict(X_train)\n",
    "y_XGB_test_pred = model1.predict(X_test)\n",
    "\n",
    "XGB_train_mse = mean_squared_error(Y_train, y_XGB_train_pred)\n",
    "XGB_train_r2 = r2_score(Y_train, y_XGB_train_pred)\n",
    "XGB_test_mse = mean_squared_error(Y_test, y_XGB_test_pred)\n",
    "XGB_test_r2 = r2_score(Y_test, y_XGB_test_pred)\n",
    "\n",
    "XGB_results = pd.DataFrame(['XGB',XGB_train_mse, XGB_train_r2, XGB_test_mse, XGB_test_r2]).transpose()\n",
    "XGB_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "# model2 = LGBMRegressor(boosting_type='gbdt',colsample_bytree=1,num_leaves=50,min_child_samples =4, max_depth=3, learning_rate=0.15, n_estimators=70,reg_alpha=1.0, reg_lambda=3.0)\n",
    "# model2.fit(X_train, Y_train)\n",
    "# y_LGBM_train_pred = model2.predict(X_train)\n",
    "# y_LGBM_test_pred = model2.predict(X_test)\n",
    "\n",
    "# LGBM_train_mse = mean_squared_error(Y_train, y_LGBM_train_pred)\n",
    "# LGBM_train_r2 = r2_score(Y_train, y_LGBM_train_pred)\n",
    "# LGBM_test_mse = mean_squared_error(Y_test, y_LGBM_test_pred)\n",
    "# LGBM_test_r2 = r2_score(Y_test, y_LGBM_test_pred)\n",
    "\n",
    "# LGBM_results = pd.DataFrame(['LGBM',LGBM_train_mse, LGBM_train_r2, LGBM_test_mse, LGBM_test_r2]).transpose()\n",
    "# LGBM_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model3 = CatBoostRegressor(iterations=500,\n",
    "                        learning_rate=.1,\n",
    "                        depth=2,\n",
    "                        model_size_reg=None,loss_function='RMSE',l2_leaf_reg=2,verbose=False)\n",
    "model3.fit(X_train, Y_train)\n",
    "y_Cat_train_pred = model3.predict(X_train)\n",
    "y_Cat_test_pred = model3.predict(X_test)\n",
    "\n",
    "Cat_train_mse = mean_squared_error(Y_train, y_Cat_train_pred)\n",
    "Cat_train_r2 = r2_score(Y_train, y_Cat_train_pred)\n",
    "Cat_test_mse = mean_squared_error(Y_test, y_Cat_test_pred)\n",
    "Cat_test_r2 = r2_score(Y_test, y_Cat_test_pred)\n",
    "\n",
    "Cat_results = pd.DataFrame(['Cat',Cat_train_mse, Cat_train_r2, Cat_test_mse, Cat_test_r2]).transpose()\n",
    "Cat_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "model4 = SGDRegressor(loss='squared_epsilon_insensitive',alpha=.0000010,penalty ='l1',max_iter=1000, eta0=0.000008,validation_fraction=0.1,average=100, random_state=42,power_t=0.0001,tol=5.2)\n",
    "model4.fit(X_train, Y_train)\n",
    "y_SGD_train_pred = model4.predict(X_train)\n",
    "y_SGD_test_pred = model4.predict(X_test)\n",
    "\n",
    "SGD_train_mse = mean_squared_error(Y_train, y_SGD_train_pred)\n",
    "SGD_train_r2 = r2_score(Y_train, y_SGD_train_pred)\n",
    "SGD_test_mse = mean_squared_error(Y_test, y_SGD_test_pred)\n",
    "SGD_test_r2 = r2_score(Y_test, y_SGD_test_pred)\n",
    "\n",
    "SGD_results = pd.DataFrame(['SGD',SGD_train_mse, SGD_train_r2, SGD_test_mse, SGD_test_r2]).transpose()\n",
    "SGD_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model5 = KernelRidge(alpha=1, kernel='linear', degree=5, coef0=5)\n",
    "model5.fit(X_train, Y_train)\n",
    "y_Kernel_train_pred = model5.predict(X_train)\n",
    "y_Kernel_test_pred = model5.predict(X_test)\n",
    "\n",
    "Kernel_train_mse = mean_squared_error(Y_train, y_Kernel_train_pred)\n",
    "Kernel_train_r2 = r2_score(Y_train, y_Kernel_train_pred)\n",
    "Kernel_test_mse = mean_squared_error(Y_test, y_Kernel_test_pred)\n",
    "Kernel_test_r2 = r2_score(Y_test, y_Kernel_test_pred)\n",
    "\n",
    "Kernel_results = pd.DataFrame(['Kernel',Kernel_train_mse, Kernel_train_r2, Kernel_test_mse, Kernel_test_r2]).transpose()\n",
    "Kernel_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model6 = ElasticNet(alpha=.0001,l1_ratio=0.00005,max_iter=100, tol=0.001, random_state=42)\n",
    "model6.fit(X_train, Y_train)\n",
    "y_EN_train_pred = model6.predict(X_train)\n",
    "y_EN_test_pred = model6.predict(X_test)\n",
    "\n",
    "EN_train_mse = mean_squared_error(Y_train, y_EN_train_pred)\n",
    "EN_train_r2 = r2_score(Y_train, y_EN_train_pred)\n",
    "EN_test_mse = mean_squared_error(Y_test, y_EN_test_pred)\n",
    "EN_test_r2 = r2_score(Y_test, y_EN_test_pred)\n",
    "\n",
    "EN_results = pd.DataFrame(['EN',EN_train_mse, EN_train_r2, EN_test_mse, EN_test_r2]).transpose()\n",
    "EN_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "model7 = BayesianRidge(n_iter=5000, tol=0.001, alpha_1=5e-03, alpha_2=1e-03, lambda_1=1e-03, lambda_2=1e-03)\n",
    "model7.fit(X_train, Y_train)\n",
    "y_Bay_train_pred = model7.predict(X_train)\n",
    "y_Bay_test_pred = model7.predict(X_test)\n",
    "\n",
    "Bay_train_mse = mean_squared_error(Y_train, y_Bay_train_pred)\n",
    "Bay_train_r2 = r2_score(Y_train, y_Bay_train_pred)\n",
    "Bay_test_mse = mean_squared_error(Y_test, y_Bay_test_pred)\n",
    "Bay_test_r2 = r2_score(Y_test, y_Bay_test_pred)\n",
    "\n",
    "Bay_results = pd.DataFrame(['Bay',Bay_train_mse, Bay_train_r2, Bay_test_mse, Bay_test_r2]).transpose()\n",
    "Bay_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model8 = GradientBoostingRegressor(alpha=.1,max_features=3,min_impurity_decrease=3,loss='absolute_error', learning_rate=0.1, n_estimators=500, max_depth=1,min_samples_leaf=1)\n",
    "model8.fit(X_train, Y_train)\n",
    "y_GBR_train_pred = model8.predict(X_train)\n",
    "y_GBR_test_pred = model8.predict(X_test)\n",
    "\n",
    "GBR_train_mse = mean_squared_error(Y_train, y_GBR_train_pred)\n",
    "GBR_train_r2 = r2_score(Y_train, y_GBR_train_pred)\n",
    "GBR_test_mse = mean_squared_error(Y_test, y_GBR_test_pred)\n",
    "GBR_test_r2 = r2_score(Y_test, y_GBR_test_pred)\n",
    "\n",
    "GBR_results = pd.DataFrame(['GBR',NR_train_mse, GBR_train_r2, GBR_test_mse, GBR_test_r2]).transpose()\n",
    "GBR_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "model9 = SVR(kernel='linear',degree=5,gamma='auto',coef0=1.0, tol=0.5, C=1.5, epsilon=0.5,cache_size=50)\n",
    "model9.fit(X_train, Y_train)\n",
    "y_SVR_train_pred = model9.predict(X_train)\n",
    "y_SVR_test_pred = model9.predict(X_test)\n",
    "\n",
    "SVR_train_mse = mean_squared_error(Y_train, y_SVR_train_pred)\n",
    "SVR_train_r2 = r2_score(Y_train, y_SVR_train_pred)\n",
    "SVR_test_mse = mean_squared_error(Y_test, y_SVR_test_pred)\n",
    "SVR_test_r2 = r2_score(Y_test, y_SVR_test_pred)\n",
    "\n",
    "SVR_results = pd.DataFrame(['SVR',SVR_train_mse, SVR_train_r2, SVR_test_mse, SVR_test_r2]).transpose()\n",
    "SVR_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model10 = DecisionTreeRegressor(min_impurity_decrease=.001,criterion='absolute_error',max_depth=19,min_samples_split=7,random_state=42)\n",
    "model10.fit(X_train, Y_train)\n",
    "y_DTR_train_pred = model10.predict(X_train)\n",
    "y_DTR_test_pred = model10.predict(X_test)\n",
    "\n",
    "DTR_train_mse = mean_squared_error(Y_train, y_DTR_train_pred)\n",
    "DTR_train_r2 = r2_score(Y_train, y_DTR_train_pred)\n",
    "DTR_test_mse = mean_squared_error(Y_test, y_DTR_test_pred)\n",
    "DTR_test_r2 = r2_score(Y_test, y_DTR_test_pred)\n",
    "\n",
    "DTR_results = pd.DataFrame(['DTR',DTR_train_mse, DTR_train_r2, DTR_test_mse, DTR_test_r2]).transpose()\n",
    "DTR_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed6eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df = pd.read_csv('arkansas1Bayer.csv')\n",
    "df = df.drop([], axis=1).dropna(axis='rows')\n",
    "mL = pd.DataFrame()\n",
    "y_rf_test_pred = rf.predict(df)\n",
    "mL['rf'] = y_rf_test_pred\n",
    "\n",
    "y_lr_test_pred = lr.predict(df)\n",
    "mL['lr'] = y_lr_test_pred\n",
    "\n",
    "y_XGB_test_pred = model1.predict(df)\n",
    "mL['XGB'] = y_XGB_test_pred\n",
    "\n",
    "# y_LGBM_test_pred = model2.predict(df)\n",
    "# mL['LGBM'] = y_LGBM_test_pred\n",
    "\n",
    "y_Cat_test_pred = model3.predict(df)\n",
    "mL['Cat'] = y_Cat_test_pred\n",
    "\n",
    "\n",
    "y_SGD_test_pred = model4.predict(df)\n",
    "mL['SGD'] = y_SGD_test_pred\n",
    "\n",
    "\n",
    "y_Kernel_test_pred = model5.predict(df)\n",
    "mL['Kernel'] = y_Kernel_test_pred\n",
    "\n",
    "\n",
    "y_EN_test_pred = model6.predict(df)\n",
    "mL['EN'] = y_EN_test_pred\n",
    "\n",
    "\n",
    "y_Bay_test_pred = model7.predict(df)\n",
    "mL['Bay'] = y_Bay_test_pred\n",
    "\n",
    "\n",
    "y_GBR_test_pred = model8.predict(df)\n",
    "mL['GBR'] = y_GBR_test_pred\n",
    "\n",
    "\n",
    "y_SVR_test_pred = model9.predict(df)\n",
    "mL['SVR'] = y_SVR_test_pred\n",
    "\n",
    "\n",
    "y_DTR_test_pred = model10.predict(df)\n",
    "mL['DTR'] = y_DTR_test_pred\n",
    "mL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc673a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "X = mL\n",
    "Y = pd.read_csv('arkansasBayer1.csv')\n",
    "#Y = dtf2.drop([], axis=1).dropna(axis='rows')\n",
    "r_array = []\n",
    "mse_array= []\n",
    "error_array= []\n",
    "for i in range(1, 2):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=.2, random_state=42)\n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Conv1D, Flatten\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 3, activation=\"relu\", input_shape=(11,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    model.fit(X_train, Y_train, batch_size=1,epochs=100, verbose=0)\n",
    "    #history = model.fit(X_train, Y_train, epochs=1000,\n",
    "     #                   validation_split=0.2, verbose=0)\n",
    "    ypred = model.predict(X_test)\n",
    "    #print(model.evaluate(X_train, Y_train))\n",
    "    #print(\"MSE: %.3f\" % mean_squared_error(Y_test, ypred))\n",
    "\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    y_rf_train_pred = model.predict(X_train)\n",
    "    y_rf_test_pred = model.predict(X_test)\n",
    "    rf_train_mse = mean_squared_error(Y_train, y_rf_train_pred)\n",
    "    rf_train_r2 = r2_score(Y_train, y_rf_train_pred)\n",
    "    rf_test_mse = mean_squared_error(Y_test, y_rf_test_pred)\n",
    "    rf_test_r2 = r2_score(Y_test, y_rf_test_pred)\n",
    "    \n",
    "\n",
    "    rf_results = pd.DataFrame(['Super Learner',rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()\n",
    "    rf_results.columns = ['Method','Training MSE','Training R2','Test MSE','Test R2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62a0400f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124227e80a4746c58cd7cf91e46df215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntText(value=0, description='Prototype'), IntText(value=0, description='lowBound1'), In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_plot(Prototype, lowBound1, highBound1, lowBound2, highBound2)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from scipy.optimize import minimize_scalar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def equation(x):\n",
    "    return dataCol[x]\n",
    "\n",
    "def find_saturation_point(dataCol, lower_bound, upper_bound, tolerance=.25):\n",
    "    # Use an iterative approach to find the saturation point\n",
    "    x = lower_bound\n",
    "    counter = 0\n",
    "    counterTolerance = 4\n",
    "\n",
    "    while x < upper_bound and counter<counterTolerance:\n",
    "        if(abs(equation(int(x+1))-equation(int(x))) < (tolerance)):\n",
    "            counter+=1\n",
    "        x += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return (x)\n",
    "\n",
    "\n",
    "def interactive_plot(Prototype,lowBound1,highBound1,lowBound2,highBound2):\n",
    "    sheet_id = '1IEFPaOT6y0N92Vu1ItKzUhrDpizdPs9j6ooBm9iXh14'\n",
    "    xls = pd.ExcelFile(f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx\")\n",
    "    sheetNum=Prototype\n",
    "    data = pd.read_excel(xls, str(sheetNum),header = 0)\n",
    "    initiData=data['CO2'].iloc[0]\n",
    "    referenceData = 429\n",
    "    updateData = referenceData/initiData\n",
    "    data[\"CO2\"] = data[\"CO2\"]*updateData\n",
    "    data = data[data.CO2 != 0]\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    global dList \n",
    "    dList=data.index.tolist()\n",
    "    dataCol=data['CO2'].tolist()\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))  # Adjust the figsize as needed\n",
    "    plt.plot(dList,dataCol)\n",
    "    plt.axvline(x=lowBound1, color = 'b', linestyle='--',)\n",
    "    plt.axvline(x=highBound1, color = 'g', linestyle='--',)\n",
    "    plt.axvline(x=lowBound2, color = 'b', linestyle='--',)\n",
    "    plt.axvline(x=highBound2, color = 'g', linestyle='--',)\n",
    "    \n",
    "    tempAverage = data['Temperature'].loc[lowBound1:highBound2].mean()\n",
    "    moistAverage = data['Moisture'].loc[lowBound1:highBound2].mean()\n",
    "\n",
    "    depth = 15\n",
    "    crop = 0\n",
    "    harvest = 0\n",
    "    slope_intercept = np.polyfit(dList,dataCol,1)\n",
    "    slope =abs(slope_intercept[0])\n",
    "\n",
    "    plt.title('Prototype '+str(sheetNum)+ ' CO2 Measurements', fontsize=16)\n",
    "    plt.ylabel('CO2 Concentration (ppm)', fontsize=16)\n",
    "    plt.xlabel('Time (minutes)', fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    if(lowBound1<highBound1 and lowBound2<highBound2):\n",
    "        print(\"First Low Boundary: \",lowBound1)\n",
    "        print(\"First High Boundary: \",highBound1)\n",
    "        saturation_point = find_saturation_point(equation, lowBound1, highBound1)\n",
    "        # print(\"Saturation Point:\", saturation_point)\n",
    "        # print(\"Saturation Y-Value:\", dataCol[int(saturation_point)])\n",
    "        print(\"Second Low Boundary: \",lowBound2)\n",
    "        print(\"Second High Boundary: \",highBound2)\n",
    "        saturation_point2 = find_saturation_point(equation, lowBound2, highBound2)\n",
    "        # print(\"Saturation Point:\", saturation_point2)\n",
    "        # print(\"Saturation Y-Value:\", dataCol[int(saturation_point2)])\n",
    "        \n",
    "        PO = dataCol[int(saturation_point2)]-dataCol[int(saturation_point)]\n",
    "        print(\"Photo-Oxidated CO2: \", PO)\n",
    "            \n",
    "        d = {'PO':[PO], 'Depth': [depth], 'Moist': [moistAverage], 'PO_Rate': [slope,] , 'Harvest': [harvest]\n",
    "             , 'Crop': [crop], 'Temp':[tempAverage]}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        smL = pd.DataFrame()\n",
    "        y_rf_test_pred = rf.predict(df)\n",
    "        smL['rf'] = y_rf_test_pred\n",
    "\n",
    "        y_lr_test_pred = lr.predict(df)\n",
    "        smL['lr'] = y_lr_test_pred\n",
    "\n",
    "        y_XGB_test_pred = model1.predict(df)\n",
    "        smL['XGB'] = y_XGB_test_pred\n",
    "\n",
    "        # y_LGBM_test_pred = model2.predict(df)\n",
    "        # smL['LGBM'] = y_LGBM_test_pred\n",
    "\n",
    "        y_Cat_test_pred = model3.predict(df)\n",
    "        smL['Cat'] = y_Cat_test_pred\n",
    "\n",
    "\n",
    "        y_SGD_test_pred = model4.predict(df)\n",
    "        smL['SGD'] = y_SGD_test_pred\n",
    "\n",
    "\n",
    "        y_Kernel_test_pred = model5.predict(df)\n",
    "        smL['Kernel'] = y_Kernel_test_pred\n",
    "\n",
    "\n",
    "        y_EN_test_pred = model6.predict(df)\n",
    "        smL['EN'] = y_EN_test_pred\n",
    "\n",
    "\n",
    "        y_Bay_test_pred = model7.predict(df)\n",
    "        smL['Bay'] = y_Bay_test_pred\n",
    "\n",
    "\n",
    "        y_GBR_test_pred = model8.predict(df)\n",
    "        smL['GBR'] = y_GBR_test_pred\n",
    "\n",
    "\n",
    "        y_SVR_test_pred = model9.predict(df)\n",
    "        smL['SVR'] = y_SVR_test_pred\n",
    "\n",
    "\n",
    "        y_DTR_test_pred = model10.predict(df)\n",
    "        smL['DTR'] = y_DTR_test_pred\n",
    "\n",
    "        ypred = model.predict(smL)        \n",
    "        print(\"\\033[1mSOC: \\033[0m\",str(*[str(row)[1:-1] for row in ypred])+\"%\")\n",
    "        print(\"Average Temperature\",str(round(tempAverage,2))+\"°C\")\n",
    "        print(\"Average Moisture\",str(round(moistAverage,2))+\"%\")\n",
    "\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print(\"Lower Boundary: \",lowBound1)\n",
    "        print(\"Higher Boundary: \",highBound1)\n",
    "        print(\"lowBound must be less than highBound\")\n",
    "\n",
    "    \n",
    "interact(interactive_plot,Prototype= widgets.IntText(),\n",
    "         lowBound1=widgets.IntText(min=min(dList),max=max(dList))\n",
    "         ,highBound1=widgets.IntText(min=min(dList),max=max(dList))\n",
    "         ,lowBound2=widgets.IntText(min=min(dList),max=max(dList))\n",
    "         ,highBound2=widgets.IntText(min=min(dList),max=max(dList)))\n",
    "\n",
    "#interact(interactive_plot, lowBound1=(min=min(dList),max=max(dList))\n",
    "#         ,highBound1=(min=min(dList),max=max(dList))\n",
    "#         ,lowBound2=(min=min(dList),max=max(dList))\n",
    "#         ,highBound2=(min=min(dList),max=max(dList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5c761f5-1369-4eb4-9a07-7dcad0a8f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(xls, '7',header = 0)\n",
    "data = data[data.CO2 != 0]\n",
    "data = data.fillna(0)\n",
    " \n",
    "dList=data.index.tolist()\n",
    "dataCol=data['CO2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd9b85d1-543e-4c6b-8073-d027c3b87bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCol[1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1691d692-c512-4513-a6b3-ced7a333dbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prototype</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>#VALUE!</th>\n",
       "      <th>Constant</th>\n",
       "      <th>CO2 Average</th>\n",
       "      <th>Temp Average</th>\n",
       "      <th>Moist Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-10-28 13:53:06.425</td>\n",
       "      <td>8</td>\n",
       "      <td>569</td>\n",
       "      <td>23.639999</td>\n",
       "      <td>12</td>\n",
       "      <td>437.614565</td>\n",
       "      <td>1.300231</td>\n",
       "      <td>#VALUE!</td>\n",
       "      <td>18.01729</td>\n",
       "      <td>63.938931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-10-28 13:54:59.525</td>\n",
       "      <td>8</td>\n",
       "      <td>566</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>435.307282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-10-28 13:55:56.083</td>\n",
       "      <td>8</td>\n",
       "      <td>563</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>12</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-10-28 13:56:52.972</td>\n",
       "      <td>8</td>\n",
       "      <td>566</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>12</td>\n",
       "      <td>435.307282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-10-28 13:57:49.545</td>\n",
       "      <td>8</td>\n",
       "      <td>562</td>\n",
       "      <td>23.430000</td>\n",
       "      <td>12</td>\n",
       "      <td>432.230906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-11-23 12:10:59.102</td>\n",
       "      <td>8</td>\n",
       "      <td>851</td>\n",
       "      <td>5.220000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-11-23 12:11:56.647</td>\n",
       "      <td>8</td>\n",
       "      <td>851</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-11-23 12:12:51.960</td>\n",
       "      <td>8</td>\n",
       "      <td>866</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-11-23 12:15:41.142</td>\n",
       "      <td>8</td>\n",
       "      <td>825</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>e00fce68dcaefb9db946ce06</td>\n",
       "      <td>2022-11-23 12:16:37.477</td>\n",
       "      <td>8</td>\n",
       "      <td>824</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Address                    Date  Prototype  CO2  \\\n",
       "0    e00fce68dcaefb9db946ce06 2022-10-28 13:53:06.425          8  569   \n",
       "1    e00fce68dcaefb9db946ce06 2022-10-28 13:54:59.525          8  566   \n",
       "2    e00fce68dcaefb9db946ce06 2022-10-28 13:55:56.083          8  563   \n",
       "3    e00fce68dcaefb9db946ce06 2022-10-28 13:56:52.972          8  566   \n",
       "4    e00fce68dcaefb9db946ce06 2022-10-28 13:57:49.545          8  562   \n",
       "..                        ...                     ...        ...  ...   \n",
       "507  e00fce68dcaefb9db946ce06 2022-11-23 12:10:59.102          8  851   \n",
       "508  e00fce68dcaefb9db946ce06 2022-11-23 12:11:56.647          8  851   \n",
       "509  e00fce68dcaefb9db946ce06 2022-11-23 12:12:51.960          8  866   \n",
       "510  e00fce68dcaefb9db946ce06 2022-11-23 12:15:41.142          8  825   \n",
       "511  e00fce68dcaefb9db946ce06 2022-11-23 12:16:37.477          8  824   \n",
       "\n",
       "     Temperature  Moisture     #VALUE!  Constant CO2 Average  Temp Average  \\\n",
       "0      23.639999        12  437.614565  1.300231     #VALUE!      18.01729   \n",
       "1      23.750000        12  435.307282  0.000000           0       0.00000   \n",
       "2      24.600000        12  433.000000  0.000000           0       0.00000   \n",
       "3      23.959999        12  435.307282  0.000000           0       0.00000   \n",
       "4      23.430000        12  432.230906  0.000000           0       0.00000   \n",
       "..           ...       ...         ...       ...         ...           ...   \n",
       "507     5.220000        47    0.000000  0.000000           0       0.00000   \n",
       "508     5.110000        47    0.000000  0.000000           0       0.00000   \n",
       "509     4.690000        47    0.000000  0.000000           0       0.00000   \n",
       "510     4.480000        47    0.000000  0.000000           0       0.00000   \n",
       "511     4.480000        47    0.000000  0.000000           0       0.00000   \n",
       "\n",
       "     Moist Average  \n",
       "0        63.938931  \n",
       "1         0.000000  \n",
       "2         0.000000  \n",
       "3         0.000000  \n",
       "4         0.000000  \n",
       "..             ...  \n",
       "507       0.000000  \n",
       "508       0.000000  \n",
       "509       0.000000  \n",
       "510       0.000000  \n",
       "511       0.000000  \n",
       "\n",
       "[499 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124cacd-6433-4a9a-a93e-7c87a88ad715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
